{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Project : Text To AI Image Generator"
      ],
      "metadata": {
        "id": "ufbkcme55nMb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**AI Image Generator with Stable Diffusion**\n",
        "\n",
        "\n",
        "This is a simple and powerful AI image generation web app built using Hugging Face's diffusers library and deployed on Gradio + Hugging Face Spaces.\n",
        "\n",
        "It uses **Stable Diffusion v1.5** to generate* high-quality images *from text prompts given by the user.\n",
        "\n",
        "-------------------------------------------------------------------------\n",
        "\n",
        " **Features**\n",
        "\n",
        " Text-to-Image generation using Stable Diffusion\n",
        "\n",
        " Clean and simple web interface via Gradio\n",
        "\n",
        " Fast image generation with GPU support (CUDA)\n",
        "\n",
        " Fully deployable and shareable via Hugging Face Spaces\n",
        "\n",
        " ------------------------------------------------------------------------\n",
        "\n",
        " **Demo**\n",
        "\n",
        " Try it here: https://<your-space-name>.huggingface.space\n",
        "(Replace with your actual Hugging Face Space URL)\n",
        "\n",
        " How It Works\n",
        "User enters a text prompt (e.g., \"a cat sitting on the moon\").\n",
        "\n",
        "The backend runs Stable Diffusion to convert text into an image.\n",
        "\n",
        "The output image is displayed on the web interface in seconds.\n",
        "\n",
        " Requirements\n",
        "These packages are required (also saved in requirements.txt):\n",
        "\n",
        "\n",
        "1.   Txt\n",
        "2.   Copy\n",
        "3.   Edit\n",
        "4.   Diffusers\n",
        "5.   Transformers\n",
        "6.   Accelerate\n",
        "7.   Safetensors\n",
        "8.   Torch\n",
        "9.   Gradio\n"
      ],
      "metadata": {
        "id": "WshfsRgbvyPr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "-------------------------------------------------------------------------\n",
        "\n"
      ],
      "metadata": {
        "id": "EvuJgxcT0ceK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1:** Installed and upgraded key HuggingFace libraries italicized text upgraded key HuggingFace libraries\n",
        "\n",
        "\n",
        "1.  Diffusers\n",
        "2.  Transformers\n",
        "\n",
        "Transformers\n",
        "Accelerate\n",
        "Safetensors -to enable use of text generation, text-to-image generation, and fast model execution with secure and efficient model weight loading."
      ],
      "metadata": {
        "id": "JsTvrbZst1E6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHBED87ABzu8",
        "outputId": "9d14d046-d522-42ce-f016-7e3f6a09f244"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: diffusers in /usr/local/lib/python3.11/dist-packages (0.34.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.54.0)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.54.1-py3-none-any.whl.metadata (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.9.0)\n",
            "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.11/dist-packages (from diffusers) (8.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from diffusers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from diffusers) (0.34.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from diffusers) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from diffusers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from diffusers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from diffusers) (0.5.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from diffusers) (11.3.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.27.0->diffusers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.27.0->diffusers) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.27.0->diffusers) (1.1.5)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata->diffusers) (3.23.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers) (2025.7.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
            "Downloading transformers-4.54.1-py3-none-any.whl (11.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m60.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, transformers\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.54.0\n",
            "    Uninstalling transformers-4.54.0:\n",
            "      Successfully uninstalled transformers-4.54.0\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 transformers-4.54.1\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (0.5.3)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install --upgrade diffusers transformers accelerate\n",
        "!pip install safetensors"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "----------------------------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "FTiP1pFEGJCe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Step 2:** Login to Hugging Face\n",
        "\n",
        "*  Used a token to authenticate access to models:\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YSFaiDRP00Fa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import gradio as gr\n",
        "from diffusers import StableDiffusionPipeline\n",
        "from huggingface_hub import login"
      ],
      "metadata": {
        "id": "b46vOtysCSqn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----------------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "SQoYjtogGPyl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3:** Load the Pretrained Model\n",
        "\n",
        "*   Used StableDiffusionPipeline from diffusers:\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7DC6kvm51OZj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Authenticate with Hugging Face\n",
        "login(\"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\")"
      ],
      "metadata": {
        "id": "Q72XjYIXCeuz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----------------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "obmLwpoTGUn-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4**: Generate Image from Prompt\n",
        "\n",
        "*   User inputs a text prompt, and the model generates an image\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mRsXBWn01dHb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Step 4: Load the pipeline\n",
        "\n",
        "pipe = StableDiffusionPipeline.from_pretrained(\n",
        "    \"runwayml/stable-diffusion-v1-5\",\n",
        "    torch_dtype=torch.float16,\n",
        "    use_safetensors=True\n",
        ")\n",
        "pipe = pipe.to(\"cuda\")\n"
      ],
      "metadata": {
        "id": "rAu1JzAlCmWS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----------------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "nhZWR_FoGWnl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 5:** Display Image\n",
        "\n",
        "*   Displayed the image using matplotlib:\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "O_btHClz1qcz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_image(prompt):\n",
        "    print(\" Prompt received:\", prompt)\n",
        "    try:\n",
        "        image = pipe(prompt).images[0]\n",
        "        print(\"Image generated successfully\")\n",
        "        return image\n",
        "    except Exception as e:\n",
        "        print(\" Error in generating image:\", str(e))  # Yeh sabse important line hai\n",
        "        return None"
      ],
      "metadata": {
        "id": "OBxilsZxCpBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----------------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "SmdP7EZuGYOd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 6 :** Building the Web Interface**\n",
        "      Why Gradio?\n",
        "\n",
        "*    Gradio provides a quick and easy way to create web interfaces for machine learning models.\n",
        "\n"
      ],
      "metadata": {
        "id": "HTvvFHty2HmL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradio UI\n",
        "demo = gr.Interface(\n",
        "    fn=generate_image,\n",
        "    inputs=gr.Textbox(label=\"Enter your image prompt\"),\n",
        "    outputs=gr.Image(type=\"pil\"),\n",
        "    title=\"Stable Diffusion Generator\",\n",
        "    description=\"Enter any creative prompt and get an AI-generated image!\"\n",
        ")\n",
        "\n",
        "# Launch UI\n",
        "demo.launch(share=True)"
      ],
      "metadata": {
        "id": "0oDH_0BBCz-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "HO2HVZvVGgBl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## **Possible Challenges You May Have Faced**\n",
        "\n",
        "### 1. **Environment and Dependency Issues**\n",
        "\n",
        "* Installing heavy libraries like `diffusers`, `transformers`, `torch`, `safetensors`take time and cause version conflicts.\n",
        "* Frequent updates of Hugging Face libraries break compatibility.\n",
        "* CUDA compatibility issues during PyTorch or Stable Diffusion usage (e.g., wrong `torch_dtype` or incompatible CUDA versions).\n",
        "* Long installation times or memory overflows due to Colab RAM/VRAM limitations.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. **Hugging Face Authentication Problems**\n",
        "\n",
        "* Token errors due to:\n",
        "\n",
        "  * Expired token\n",
        "  * Wrong token scope (read vs write)\n",
        "  * Using `login()` in the wrong order or without internet access\n",
        "\n",
        "---\n",
        "\n",
        "### 3. **Model Loading Errors**\n",
        "\n",
        "* Issues with `StableDiffusionPipeline`:\n",
        "\n",
        "  * `use_safetensors=True` but the model doesn’t support it\n",
        "  * `torch_dtype=torch.float16` not supported on CPU\n",
        "  * Colab free tier  not have GPU available, which can cause the pipeline to crash or be slow\n",
        "\n",
        "---\n",
        "\n",
        "### 4. **Image Generation Failures**\n",
        "\n",
        "* Prompt too long or too short causing `pipe(prompt).images[0]` to fail\n",
        "* Timeout due to GPU overload or slow Hugging Face response\n",
        "* Output not returned as expected — resulting in corrupted or blank images\n",
        "\n",
        "---\n",
        "\n",
        "### 5. **Debugging and Exception Handling**\n",
        "\n",
        "* Lack of detailed error messages makes debugging harder\n",
        "* Your `try/except` block is good, but adding full tracebacks could improve diagnostics\n",
        "\n",
        "---\n",
        "\n",
        "### 6. **Gradio Deployment Challenges**\n",
        "\n",
        "* Internet issues during `demo.launch(share=True)` can cause interface failures\n",
        "* Gradio UI may lag in Colab environments\n",
        "* Colab runtime disconnects or times out frequently\n",
        "* Deploying to Hugging Face Spaces requires additional setup: GitHub integration, model card, etc.\n",
        "\n",
        "---\n",
        "\n",
        "### 7. **Hardware Limitations (Colab)**\n",
        "\n",
        "* Free GPU quota exceeded message\n",
        "* Out-of-memory error during image generation with high-resolution prompts\n",
        "* Colab shuts down runtime due to inactivity if testing takes too long\n",
        "\n",
        "---\n",
        "\n",
        "### 8. **Performance and Usability Gaps**\n",
        "\n",
        "* No visual feedback (like a progress bar) during image generation\n",
        "* No input validation — blank or broken prompt may crash the pipeline\n",
        "* Output image display lacks metadata, download options, or customization\n",
        "\n",
        "---\n",
        "\n",
        "### 9. **Security and Safety Concerns**\n",
        "\n",
        "* Hardcoded Hugging Face access token is visible in your notebook — this is a security vulnerability\n",
        "* The app allows open-ended text input, which could be misused for inappropriate prompt generation\n",
        "* If `safety_checker=None` is used, NSFW content may be generated\n",
        "\n",
        "---\n",
        "\n",
        "### 10. **Missing Functional Enhancements**\n",
        "\n",
        "* No prompt history or way to store previously generated images\n",
        "* No control over resolution, number of images, or visual style\n",
        "* No download/save option for the generated image\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "iUVqS85cHnF9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "9SVzm3_9cPqb"
      }
    }
  ]
}